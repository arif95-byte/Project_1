{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dbece03-2d60-4a0d-b85f-4edca454a12c",
   "metadata": {},
   "source": [
    "# Binary Classification with a Bank Churn Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb3ac67-df04-4aff-aefc-9b1c6c11fafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  Exited\n",
      "0  165034     0.5\n",
      "1  165035     0.5\n",
      "2  165036     0.5\n",
      "3  165037     0.5\n",
      "4  165038     0.5\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
      "2   2    15694510           Hsueh          678    France   Male  40.0      10   \n",
      "3   3    15741417             Kao          581    France   Male  34.0       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male  33.0       5   \n",
      "\n",
      "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
      "0       0.00              2        1.0             0.0        181449.97   \n",
      "1       0.00              2        1.0             1.0         49503.50   \n",
      "2       0.00              2        1.0             0.0        184866.69   \n",
      "3  148882.54              1        1.0             1.0         84560.88   \n",
      "4       0.00              2        1.0             1.0         15068.83   \n",
      "\n",
      "   Exited  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "       id  CustomerId    Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0  165034    15773898   Lucchese          586    France  Female  23.0       2   \n",
      "1  165035    15782418       Nott          683    France  Female  46.0       2   \n",
      "2  165036    15807120         K?          656    France  Female  34.0       7   \n",
      "3  165037    15808905  O'Donnell          681    France    Male  36.0       8   \n",
      "4  165038    15607314    Higgins          752   Germany    Male  38.0      10   \n",
      "\n",
      "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0       0.00              2        0.0             1.0        160976.75  \n",
      "1       0.00              1        1.0             0.0         72549.27  \n",
      "2       0.00              2        1.0             0.0        138882.09  \n",
      "3       0.00              1        1.0             0.0        113931.57  \n",
      "4  121263.62              1        1.0             0.0        139431.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the CSV file\n",
    "file = pd.read_csv('sample_submission.csv')\n",
    "train_file = pd.read_csv('train.csv')\n",
    "test_file = pd.read_csv('test.csv')\n",
    "\n",
    "#Display the first few rows of the dataframe\n",
    "print(file.head())\n",
    "print(train_file.head())\n",
    "print(test_file.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916eb05-224e-40d7-8312-06be42494f7a",
   "metadata": {},
   "source": [
    "# Build a predictive model:\n",
    "1. Data Preprocessing: Handle missing values, encode categorical variables, and normalize/standardize numerical features.\n",
    "2. Model Selection: Choose a suitable machine learning model.\n",
    "3. Training the Model: Use the training data to train the model.\n",
    "4. Model Evaluation: Evaluate the model's performance on the training data using precision, recall, and AUC-ROC score.\n",
    "5. Predictions: Use the trained model to predict 'Exited' for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d060133c-68ac-4d80-b9ed-e88181ca8a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165034, 2812), (132027, 2812), (33007, 2812))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separating features and target variable in training data\n",
    "X_train = train_file.drop('Exited', axis=1)\n",
    "y_train = train_file['Exited']\n",
    "\n",
    "# Preprocessing Steps:\n",
    "# 1. Impute missing values for numerical columns\n",
    "# 2. Standardize numerical columns\n",
    "# 3. One-hot encode categorical columns\n",
    "\n",
    "# Identifying numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Creating transformers for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combining transformers into a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Preprocessing the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Splitting the processed training data for model evaluation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_preprocessed, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_preprocessed.shape, X_train_split.shape, X_val_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a318a-48da-4dbb-8343-b16833496bef",
   "metadata": {},
   "source": [
    "# 1. Preprocessing Steps:\n",
    "- Missing values in numerical columns were imputed with the mean.\n",
    "- Numerical columns were standardized.\n",
    "- Categorical columns were one-hot encoded.\n",
    "# 2. Dataset Transformation:\n",
    "- The training data has been transformed into a format suitable for machine learning models.\n",
    "- The number of features has increased to 2812 due to one-hot encoding of categorical variables.\n",
    "# 3. Splitting for Model Evaluation:\n",
    "- The preprocessed training data has been split into two parts:\n",
    "- A training set (80%) for training the model.\n",
    "- A validation set (20%) for evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5345a-e8d1-455d-96d5-540517dd0fb2",
   "metadata": {},
   "source": [
    "I will select a machine learning model, train it using the training set, and evaluate its performance on the validation set using precision, recall, and AUC-ROC score.\n",
    "Given the nature of the data (a binary classification problem), Random Forest Classifier is a suitable choice for this demonstration.\n",
    "\n",
    "I will use a smaller sample of the training data for quicker model training and evaluation due to the large size of the dataset and the high number of features after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3885a26d-2cc8-4faa-9e4b-87917c5e26d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7852687852687853, 0.38015815959741195, 0.6762029858327916)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Reducing the size of the training set by sampling\n",
    "sampled_X_train_split, sampled_y_train_split = resample(X_train_split, y_train_split, n_samples=10000, random_state=42)\n",
    "\n",
    "# Training the Random Forest Classifier on the sampled data\n",
    "rf_model_sampled = RandomForestClassifier(random_state=42)\n",
    "rf_model_sampled.fit(sampled_X_train_split, sampled_y_train_split)\n",
    "\n",
    "# Predicting on the validation set\n",
    "sampled_y_pred_val = rf_model_sampled.predict(X_val_split)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "sampled_precision_val = precision_score(y_val_split, sampled_y_pred_val)\n",
    "sampled_recall_val = recall_score(y_val_split, sampled_y_pred_val)\n",
    "sampled_roc_auc_val = roc_auc_score(y_val_split, sampled_y_pred_val)\n",
    "\n",
    "sampled_precision_val, sampled_recall_val, sampled_roc_auc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33976fc8-a94d-45af-876b-cdd11d7b395b",
   "metadata": {},
   "source": [
    "Precision : 78.53%\n",
    "Recall : 38.02%\n",
    "ROC-AUC : 67.62%\n",
    "\n",
    "For more accurate and robust predictions, consider using the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e81ff78-88b0-4e26-a855-15804f979bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Exited\n",
       "0  165034    0.12\n",
       "1  165035    0.68\n",
       "2  165036    0.11\n",
       "3  165037    0.33\n",
       "4  165038    0.34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the test data\n",
    "X_test_preprocessed = preprocessor.transform(test_file)\n",
    "\n",
    "# Making predictions on the test dataset\n",
    "test_predictions = rf_model_sampled.predict_proba(X_test_preprocessed)[:, 1]\n",
    "\n",
    "# Creating a DataFrame for the predictions\n",
    "prediction_df = pd.DataFrame({\n",
    "    'id' : test_file['id'],\n",
    "    'Exited': test_predictions\n",
    "})\n",
    "\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586aab0-1323-449e-b7bb-c25a99f7393b",
   "metadata": {},
   "source": [
    "The predictions are in the format of a probability between 0 and 1, where higher values indicate a higher likelihood of the 'Exited' event."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
